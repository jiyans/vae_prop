{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab46fe9e",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b30399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ca413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm, torch, random, datasets, math, fastcore.all as fc, numpy as np, matplotlib as mpl, matplotlib.pyplot as plt\n",
    "\n",
    "# import k_diffusion as K,\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF, torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "from pathlib import Path\n",
    "from torch.nn import init\n",
    "from fastcore.foundation import L\n",
    "from torch import nn, tensor\n",
    "import datasets as ds\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "from torcheval.metrics import MulticlassAccuracy, Mean, Metric\n",
    "from functools import partial\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import optim\n",
    "from einops import rearrange\n",
    "\n",
    "from miniai.datasets import *\n",
    "from miniai.conv import *\n",
    "from miniai.learner import *\n",
    "from miniai.activations import *\n",
    "from miniai.training import *\n",
    "from miniai.init import *\n",
    "from miniai.sgd import *\n",
    "from miniai.resnet import *\n",
    "from miniai.augment import *\n",
    "from miniai.accel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams[\"image.cmap\"] = \"gray_r\"\n",
    "mpl.rcParams[\"figure.dpi\"] = 70\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "set_seed(42)\n",
    "if fc.defaults.cpus > 8:\n",
    "    fc.defaults.cpus = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16efdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "iw = partial(init_weights, leaky=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac4a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "# Create pandas DataFrame\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"athletic_ability\": np.random.normal(0, 1, n_samples),\n",
    "        \"academic_performance\": np.random.normal(0, 1, n_samples),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add scholarship (collider)\n",
    "df[\"scholarship\"] = (\n",
    "    0.7 * df.athletic_ability\n",
    "    + 0.7 * df.academic_performance\n",
    "    + np.random.normal(0, 0.1, n_samples)\n",
    ")\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "dataset = ds.Dataset.from_pandas(df)\n",
    "\n",
    "# Split into train/validation\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "\n",
    "# Transform function to convert to tensors\n",
    "@inplace\n",
    "def transformi(b):\n",
    "    features = torch.stack(\n",
    "        [\n",
    "            torch.tensor(b[\"athletic_ability\"], dtype=torch.float32),\n",
    "            torch.tensor(b[\"academic_performance\"], dtype=torch.float32),\n",
    "            torch.tensor(b[\"scholarship\"], dtype=torch.float32),\n",
    "        ]\n",
    "    ).T  # Transpose to get correct shape [batch_size, features]\n",
    "    b[\"xl\"] = features\n",
    "    b[\"yl\"] = features\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    xl = torch.stack([item[\"xl\"] for item in batch])\n",
    "    yl = torch.stack([item[\"yl\"] for item in batch])\n",
    "    return xl, yl\n",
    "\n",
    "\n",
    "tds = dataset.with_transform(transformi)\n",
    "\n",
    "# Create DataLoaders\n",
    "dls = DataLoaders(\n",
    "    *get_dls(tds[\"train\"], tds[\"test\"], bs=64, num_workers=8, collate_fn=collate)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18be7aa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# Test it\n",
    "dl = dls.train\n",
    "xb, yb = b = next(iter(dl))\n",
    "print(\"Shape of xb:\", xb.shape)  # Should print something like torch.Size([64, 3])\n",
    "\n",
    "# Apply transforms\n",
    "\n",
    "ni = 3  # input dimensions\n",
    "nh = 32  # hidden dimensions\n",
    "nl = 2  # latent dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e9fee8",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba93659f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# sd vae is 3 down, 1 no-down, mid, conv, sampling, conv, mid, 3 up, 1 no-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefad040",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(lin(ni, nh), lin(nh, nh))\n",
    "        self.mu, self.lv = lin(nh, nl, act=None), lin(nh, nl, act=None)\n",
    "        self.dec = nn.Sequential(lin(nl, nh), lin(nh, nh), lin(nh, ni, act=None))\n",
    "        iw(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        mu, lv = self.mu(x), self.lv(x)\n",
    "        z = mu + (0.5 * lv).exp() * torch.randn_like(lv)\n",
    "        return self.dec(z), mu, lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18cbfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kld_loss(inp, x):\n",
    "    x_hat, mu, lv = inp\n",
    "    return -0.5 * (1 + lv - mu.pow(2) - lv.exp()).mean()\n",
    "\n",
    "\n",
    "def bce_loss(inp, x):\n",
    "    return F.binary_cross_entropy_with_logits(inp[0], x)\n",
    "\n",
    "\n",
    "def vae_loss(inp, x):\n",
    "    return kld_loss(inp, x) + bce_loss(inp, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0f4f50",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "x = torch.linspace(-3, 3, 100)\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(x, -0.5 * (1 + x - x.exp()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a6f519",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "**Question**: What would happen if the variance of the latents were very low? What if they were very high?\n",
    "\n",
    "**Bing**: If the variance of the latents were very low, then the encoder distribution would be very peaked and concentrated around the mean. This would make the latent space less diverse and expressive, and limit the ability of the decoder to reconstruct the data accurately. It would also make it harder to generate new data that are different from the training data.\n",
    "\n",
    "If the variance of the latents were very high, then the encoder distribution would be very spread out and diffuse. This would make the latent space more noisy and random, and reduce the correlation between the latent codes and the data. It would also make it easier to generate new data that are unrealistic or nonsensical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b89aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuncMetric(Mean):\n",
    "    def __init__(self, fn, device=None):\n",
    "        super().__init__(device=device)\n",
    "        self.fn = fn\n",
    "\n",
    "    def update(self, inp, targets):\n",
    "        self.weighted_sum += self.fn(inp, targets)\n",
    "        self.weights += 1\n",
    "\n",
    "\n",
    "def init_weights(m, leaky=0.0):\n",
    "    if isinstance(m, (nn.Conv1d, nn.Conv2d, nn.Conv3d, nn.Linear)):\n",
    "        init.kaiming_normal_(m.weight, a=leaky)\n",
    "\n",
    "\n",
    "iw = partial(init_weights, leaky=0.2)\n",
    "\n",
    "\n",
    "def lin(ni, nf, act=nn.SiLU, norm=nn.BatchNorm1d, bias=True):\n",
    "    layers = nn.Sequential(nn.Linear(ni, nf, bias=bias))\n",
    "    if act:\n",
    "        layers.append(act())\n",
    "    if norm:\n",
    "        layers.append(norm(nf))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b93c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricsCB(kld=FuncMetric(kld_loss), bce=FuncMetric(bce_loss))\n",
    "astats = ActivationStats(fc.risinstance(GeneralRelu))\n",
    "opt_func = partial(optim.Adam, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6e7338",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-2\n",
    "epochs = 20\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "cbs = [\n",
    "    # DeviceCB(device=\"mps\"),\n",
    "    ProgressCB(plot=True),\n",
    "    metrics,\n",
    "    BatchSchedCB(sched),\n",
    "    # astats\n",
    "    TrainCB(),\n",
    "    # MixedPrecision(),\n",
    "]\n",
    "model = VAE()\n",
    "learn = Learner(model, dls, vae_loss, lr=lr, cbs=cbs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9edc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dc8b45",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## VAE Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0fbda1",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae_prop",
   "language": "python",
   "name": "vae_prop"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}